{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Clasificación de imágenes.\n",
        "\n",
        "**Autor: German Preciat**; Universidad de Guadalajara\n",
        "\n",
        "**Carrera: Ing. Biomédica**\n",
        "\n",
        "**Materia: Analisis de datos clínicos**\n",
        "\n",
        "**Contacto: german.preciat@academicos.udg.mx**\n",
        "\n",
        "La meta de este ejercicio es construir y entrenar un modelo de aprendizaje profundo (capas ocultas) para la clasificación de imágenes de prendas de vestir.\n",
        "\n",
        "**Pasos**:\n",
        "\n",
        "1. **Configuración del Entorno**: Configurar un entorno de desarrollo en Google Colab, aprovechando las bibliotecas fundamentales como TensorFlow.\n",
        "\n",
        "2. **Preparación de Datos**: Explorar y preparar la base de datos de imágenes de ropa, comprendiendo la importancia de la estructura de los datos para el entrenamiento efectivo del modelo.\n",
        "\n",
        "3. **Diseño del Modelo**: Construir un modelo de clasificación de imágenes utilizando TensorFlow, entendiendo los conceptos clave como capas, funciones de activación y optimizadores.\n",
        "\n",
        "4. **Entrenamiento del Modelo**: Experimentar con el proceso de entrenamiento, ajustando parámetros y observando cómo el modelo aprende de los datos.\n",
        "\n",
        "5. **Evaluación del Modelo**: Evaluar la precisión y el rendimiento del modelo en un conjunto de datos de prueba, comprendiendo la importancia de la validación para medir la eficacia del modelo.\n",
        "\n",
        "Al completar estos pasos, se habrán desarrollado habilidades prácticas en análisis de imágenes, aprendizaje profundo y TensorFlow, sentando las bases para proyectos más avanzados y aplicaciones en el campo de la visión por computadora.\n"
      ],
      "metadata": {
        "id": "T7R4oPCz-VuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 1: Importación de Bibliotecas y Conjunto de Datos**\n",
        "\n",
        "- Importa TensorFlow y otras bibliotecas necesarias.\n",
        "- Utiliza `tf.keras.datasets` para cargar el conjunto de datos de Fashion MNIST (un conjunto de datos de imágenes de ropa)."
      ],
      "metadata": {
        "id": "TpwzrnZM-qkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar datos\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "JFtRvA80-tIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "``(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()``\n",
        "\n",
        "utiliza la función load_data() de `TensorFlow` para cargar el conjunto de datos Fashion MNIST. Este conjunto de datos es comúnmente utilizado en tareas de aprendizaje automático, especialmente en la visión por computadora, como un reemplazo más simple del conjunto de datos MNIST.\n",
        "\n",
        "La descomposición `(train_images, train_labels)`, `(test_images, test_labels)` significa que el conjunto de entrenamiento se divide en dos partes: `train_images` contiene las imágenes que se utilizarán para entrenar el modelo, y `train_labels` contiene las etiquetas correspondientes para esas imágenes. Lo mismo se aplica al conjunto de prueba, donde test_images son las imágenes de prueba y `test_labels` son las etiquetas asociadas.\n",
        "\n",
        "En resumen, se está cargando el conjunto de datos Fashion MNIST y dividiéndolo en imágenes de entrenamiento, etiquetas de entrenamiento, imágenes de prueba y etiquetas de prueba. Este conjunto de datos se utiliza comúnmente para tareas de clasificación de imágenes, donde el objetivo es entrenar un modelo para clasificar prendas de vestir en categorías específicas."
      ],
      "metadata": {
        "id": "rF0o6EC7-xPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Paso 2: Exploración de Datos**\n",
        "\n",
        "- Visualiza algunas imágenes del conjunto de datos.\n",
        "- Muestra estadísticas básicas sobre el conjunto de datos."
      ],
      "metadata": {
        "id": "H5pld-tN-0p2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Visualizar imágenes aleatorias\n",
        "plt.figure(figsize=(10, 10))\n",
        "random_indices = np.random.randint(0, len(train_images), size=25)\n",
        "\n",
        "for i, index in enumerate(random_indices):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.imshow(train_images[index], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Mostrar estadísticas\n",
        "print(\"Número de imágenes de entrenamiento:\", len(train_images))\n",
        "print(\"Número de imágenes de prueba:\", len(test_images))\n",
        "print(\"Forma de una imagen:\", train_images[0].shape)"
      ],
      "metadata": {
        "id": "54RuKvfX-2_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 3: Preprocesamiento de Datos**\n",
        "\n",
        "- Normaliza las imágenes.\n",
        "\n",
        "Las imágenes originales suelen tener píxeles con valores que van desde 0 hasta 255, donde 0 representa la intensidad mínima (negro) y 255 la intensidad máxima (blanco). Normalizar consiste en escalar estos valores para que estén en el rango de 0 a 1. Esto ayuda al modelo de la red neuronal a converger más rápido durante el entrenamiento y a mejorar la generalización del modelo.\n",
        "En este caso, se divide cada valor de píxel en las imágenes de entrenamiento y prueba por 255.0. Por lo tanto, después de esta operación, los valores de píxeles estarán en el rango [0, 1].\n",
        "\n",
        "- Convierte las etiquetas a categorías.\n",
        "\n",
        "Las etiquetas originales son simplemente números enteros que representan las clases (por ejemplo, 0 para camisetas, 1 para pantalones, etc.). Sin embargo, para entrenar un modelo de clasificación con TensorFlow, es común convertir estas etiquetas en formato categórico. Esto se hace mediante la técnica de \"one-hot encoding\", donde cada etiqueta se convierte en un vector binario que representa la clase.\n",
        "La función `to_categorical` de TensorFlow se utiliza para realizar esta conversión. En este caso, hay 10 clases en total , y por lo tanto, se especifica 10 como el número total de clases. Cada etiqueta se convierte en un vector de longitud 10, con un 1 en la posición correspondiente a la clase y 0 en todas las demás posiciones."
      ],
      "metadata": {
        "id": "gZraJbhu-3xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar imágenes\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Convertir etiquetas a categorías\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)"
      ],
      "metadata": {
        "id": "bhwydKl0-_pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Paso 4: Construcción del Modelo**\n",
        "\n",
        "- Crea un modelo secuencial simple.\n",
        "- Añade capas convolucionales y de pooling.\n"
      ],
      "metadata": {
        "id": "Dt9GFTdD_AMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear modelo\n",
        "model = models.Sequential()"
      ],
      "metadata": {
        "id": "aBzlpdQS_DYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crea un modelo secuencial, que es una pila lineal de capas. Los modelos secuenciales son apropiados para una pila simple de capas donde cada capa tiene exactamente un tensor de entrada y un tensor de salida."
      ],
      "metadata": {
        "id": "-udlvEGZ_FbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Añadir capas\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "metadata": {
        "id": "J-USbFEn_I8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Paso 5: Compilación y Entrenamiento del Modelo**\n",
        "\n",
        "- Compila el modelo con una función de pérdida y un optimizador.\n",
        "- Entrena el modelo con el conjunto de datos de entrenamiento.\n"
      ],
      "metadata": {
        "id": "qnVm22fF_KpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar modelo\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar modelo\n",
        "history = model.fit(train_images[..., tf.newaxis], train_labels, epochs=10, validation_data=(test_images[..., tf.newaxis], test_labels))"
      ],
      "metadata": {
        "id": "GZ0YnQEg_OFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Paso 6: Evaluación del Modelo y Visualización**\n",
        "\n",
        "- Evalúa el modelo con el conjunto de datos de prueba.\n",
        "- Visualiza las métricas de entrenamiento y validación.\n"
      ],
      "metadata": {
        "id": "FsfZkcE5_NSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar modelo\n",
        "test_loss, test_acc = model.evaluate(test_images[..., tf.newaxis], test_labels, verbose=2)\n",
        "print('\\nExactitud en el conjunto de prueba:', test_acc)\n",
        "\n",
        "# Visualizar métricas\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Exactitud')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wwsssZ0l_TdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tfrkpRxR_V_q"
      }
    }
  ]
}